digraph {
	graph [size="12,12"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140582388592032 [label="
 (10, 2)" fillcolor=darkolivegreen1]
	140582803478640 [label=PowBackward0]
	140582803479456 -> 140582803478640
	140582803479456 [label=AddBackward0]
	140582803479936 -> 140582803479456
	140582803479936 [label=AddmmBackward0]
	140582803479312 -> 140582803479936
	140599848347008 [label="score_model.8.bias
 (2)" fillcolor=lightblue]
	140599848347008 -> 140582803479312
	140582803479312 [label=AccumulateGrad]
	140582803481040 -> 140582803479936
	140582803481040 [label=SiluBackward0]
	140582803479840 -> 140582803481040
	140582803479840 [label=AddmmBackward0]
	140582803481328 -> 140582803479840
	140599848346928 [label="score_model.6.bias
 (64)" fillcolor=lightblue]
	140599848346928 -> 140582803481328
	140582803481328 [label=AccumulateGrad]
	140582803480512 -> 140582803479840
	140582803480512 [label=SiluBackward0]
	140582803481376 -> 140582803480512
	140582803481376 [label=AddmmBackward0]
	140582803481616 -> 140582803481376
	140599848347248 [label="score_model.4.bias
 (64)" fillcolor=lightblue]
	140599848347248 -> 140582803481616
	140582803481616 [label=AccumulateGrad]
	140582803481904 -> 140582803481376
	140582803481904 [label=SiluBackward0]
	140582803482000 -> 140582803481904
	140582803482000 [label=AddmmBackward0]
	140582803481232 -> 140582803482000
	140599848347488 [label="score_model.2.bias
 (64)" fillcolor=lightblue]
	140599848347488 -> 140582803481232
	140582803481232 [label=AccumulateGrad]
	140582803481712 -> 140582803482000
	140582803481712 [label=SiluBackward0]
	140582803481424 -> 140582803481712
	140582803481424 [label=AddmmBackward0]
	140582803482336 -> 140582803481424
	140599848348288 [label="score_model.0.bias
 (64)" fillcolor=lightblue]
	140599848348288 -> 140582803482336
	140582803482336 [label=AccumulateGrad]
	140582803481760 -> 140582803481424
	140582803481760 [label=TBackward0]
	140582803481808 -> 140582803481760
	140599848348448 [label="score_model.0.weight
 (64, 2)" fillcolor=lightblue]
	140599848348448 -> 140582803481808
	140582803481808 [label=AccumulateGrad]
	140582803481136 -> 140582803482000
	140582803481136 [label=TBackward0]
	140582803482144 -> 140582803481136
	140599848347568 [label="score_model.2.weight
 (64, 64)" fillcolor=lightblue]
	140599848347568 -> 140582803482144
	140582803482144 [label=AccumulateGrad]
	140582803481184 -> 140582803481376
	140582803481184 [label=TBackward0]
	140582803480608 -> 140582803481184
	140599848347328 [label="score_model.4.weight
 (64, 64)" fillcolor=lightblue]
	140599848347328 -> 140582803480608
	140582803480608 [label=AccumulateGrad]
	140582803478400 -> 140582803479840
	140582803478400 [label=TBackward0]
	140582803481280 -> 140582803478400
	140599848346768 [label="score_model.6.weight
 (64, 64)" fillcolor=lightblue]
	140599848346768 -> 140582803481280
	140582803481280 [label=AccumulateGrad]
	140582803478544 -> 140582803479936
	140582803478544 [label=TBackward0]
	140582803481952 -> 140582803478544
	140599848347088 [label="score_model.8.weight
 (2, 64)" fillcolor=lightblue]
	140599848347088 -> 140582803481952
	140582803481952 [label=AccumulateGrad]
	140582803478640 -> 140582388592032
}
